{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and store STOOQ data\n",
    "Inspired by code from Stefan Jansen github repository related to his book [Machine Learning for Algorithmic Trading - Second Edition](https://github.com/stefan-jansen/machine-learning-for-trading)\n",
    "\n",
    "As mentioned [here](https://github.com/stefan-jansen/machine-learning-for-trading/issues/82), STOOQ has disabled automatic download. Therefore, in order to fetch data files, it can be done manually from [STOOQ](https://stooq.com/db/h/).\n",
    "\n",
    "---\n",
    "Here, implemented data loading process of already manually downloaded files, and storing it in the [HDF5](https://www.loc.gov/preservation/digital/formats/fdd/fdd000229.shtml) format. NOTE, that the HDF5 store location would later be used in configuration (see also: `config.yaml`).\n",
    "\n",
    "\n",
    "> NOTE: the `ticker` in STOOQ data files is not the `symbol` that's available elsewhere\n",
    "> * `ticker`: `KGH`, `PKN`, ..\n",
    "> * `symbol`: `KGHM`, `PKNORLEN`, ..\n",
    ">\n",
    "> that might require additional conversion (e.g. fetching ticker symbols), but is not necessary for the `stock-ml` project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile as zip\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sure data files exist at given location\n",
    "\n",
    "Expected the downloaded files to exist in the folder of  `DATA_ROOT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_ROOT = Path('/Data/stooq')\n",
    "DATA_STORE = DATA_ROOT.joinpath('assets.h5')\n",
    "DATA_EXTRACT = DATA_ROOT.joinpath('extract')\n",
    "\n",
    "assert DATA_ROOT.exists(), f'Data folder not found {DATA_ROOT}'\n",
    "if not DATA_EXTRACT.exists(): DATA_EXTRACT.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_data_files = {\n",
    "    'pl': ['/wse stocks/', '/nc stocks/', '/wse indices/'] \n",
    "}\n",
    "archives = [DATA_ROOT.joinpath(f'd_{market}_txt.zip') for market in market_data_files.keys()]\n",
    "assert all(archive.exists() for archive in archives), f\"Some data files not found: {str([archive for archive in archives if not archive.exists()])}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_file(market:str) -> Path:\n",
    "    return DATA_ROOT.joinpath(f'd_{market}_txt.zip')\n",
    "assert all(get_data_file(market_file).exists() for market_file in market_data_files.keys()), f\"Some data files not found\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 263/882 [00:00<00:00, 1315.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '\\\\Data\\\\stooq\\\\extract\\\\pl\\\\data\\\\daily\\\\pl\\\\nc stocks\\\\aux.txt'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 395/882 [00:00<00:00, 1167.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '\\\\Data\\\\stooq\\\\extract\\\\pl\\\\data\\\\daily\\\\pl\\\\nc stocks\\\\prn.txt'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 882/882 [00:00<00:00, 961.06it/s] \n"
     ]
    }
   ],
   "source": [
    "for market_file in market_data_files.keys():\n",
    "    if not DATA_EXTRACT.joinpath(market_file).exists(): DATA_EXTRACT.joinpath(market_file).mkdir()\n",
    "    with zip.ZipFile(get_data_file(market_file)) as zip_file:\n",
    "        to_extract = [file for file in zip_file.namelist() if any(extract_folder in file for extract_folder in  market_data_files[market_file])]\n",
    "        for file in tqdm(to_extract):\n",
    "            try:\n",
    "                zip_file.extract(file, DATA_EXTRACT.joinpath(market_file))\n",
    "            except FileNotFoundError as ex:\n",
    "                print(f'{ex}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data extract and transform\n",
    "\n",
    "Extract \n",
    " from txt files, transform to pandas DataFrames, with certain structure, load to local HDF store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\nc stocks\\01c.txt \n",
      " ['<TICKER>,<PER>,<DATE>,<TIME>,<OPEN>,<HIGH>,<LOW>,<CLOSE>,<VOL>,<OPENINT>\\n']\n"
     ]
    }
   ],
   "source": [
    "files = DATA_EXTRACT.glob('**/*.txt')\n",
    "sample_file = next(files)\n",
    "with open(sample_file) as f:\n",
    "    print(sample_file,'\\n', f.readlines(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data(\n",
    "        data_file:Path,\n",
    "        columns_map:dict = {\n",
    "            '<DATE>':'date',\n",
    "            '<TICKER>':'stock',\n",
    "            '<OPEN>':'open',\n",
    "            '<HIGH>':'high',\n",
    "            '<LOW>':'low',\n",
    "            '<CLOSE>':'close',\n",
    "            '<VOL>':'volume'\n",
    "            }    \n",
    "        ) -> Optional[pd.DataFrame]:\n",
    "    \n",
    "    data = pd.read_csv(\n",
    "        data_file, \n",
    "        header=0,                                                   # header in first row\n",
    "        parse_dates=['<DATE>'],                                     # date in certain column\n",
    "        usecols=list(columns_map.keys()),                           # ignore other columns\n",
    "        index_col=None                                              # index will be set later\n",
    "    )\n",
    "    data.rename(columns=columns_map, inplace=True)                  # use well-known column names\n",
    "    data.set_index(['date','stock'], inplace=True)                  # set multiindex (for further merge)\n",
    "    data = data[~data.index.duplicated(keep='first')].sort_index()  # remove duplicates (!)\n",
    "    data['volume'] = data['volume'].astype(int)                     # no fractional volume / positinos\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "877it [01:34,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded to HDFStore.\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\c249l.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\c24n3l.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\dbe1.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\iburu.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\invgl.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\invsl.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\ipgpa.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\ipogparpa.pl.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\leb.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\lkburu.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\lkdvgl.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\lkdvsl.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\lkpgpa.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\lkq3rt.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\lpkoal.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\lpkoas.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\lpkogbl.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\lpkoso.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\lpzupl.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\lqmfiz.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\lqntum.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\lqrcus.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\ls24n3l.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\lvzpskl.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\mcm.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\mparwx.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\mpfiz.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\mprbpl.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\mwfoprl.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\ncpfiz.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\ofoprl.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\opppfz.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\oprtl.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\or1rtl.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\pcm.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\pettpl.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\pgnpel.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\phmbsz.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\php254.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\phrgnk.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\phrojp.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\pkoso.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\pzupl.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\qmfiz.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\tppfz.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\urt1.txt :  No columns to parse from file\n",
      "pl/\\Data\\stooq\\extract\\pl\\data\\daily\\pl\\wse stocks\\urta.txt :  invalid combination of [values_axes] on appending data [name->open,cname->open,dtype->int64,kind->integer,shape->(1, 16)] vs current table [name->open,cname->open,dtype->float64,kind->float,shape->None]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "files = DATA_EXTRACT.glob('**/*.txt')\n",
    "\n",
    "load_errors = {}\n",
    "if DATA_STORE.exists(): DATA_STORE.unlink()\n",
    "for market in market_data_files.keys():\n",
    "    with pd.HDFStore(DATA_STORE, mode='w') as store:\n",
    "        for file in tqdm(files):\n",
    "            try:\n",
    "                data = load_data(file)\n",
    "                store.put(f'{market}/prices', data, format='table', append=True, data_columns=True, min_itemsize={'stock' : 15}) # type: ignore \n",
    "            except Exception as e:\n",
    "                load_errors[f'{market}/{file}'] = str(e)\n",
    "print(f'Data loaded to HDFStore {DATA_STORE}')\n",
    "if load_errors: \n",
    "    for file, error in load_errors.items():\n",
    "        print(file, ': ', error)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
